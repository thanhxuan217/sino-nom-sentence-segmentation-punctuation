{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea578dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:11:49.438046Z",
     "iopub.status.busy": "2026-01-24T15:11:49.437811Z",
     "iopub.status.idle": "2026-01-24T15:11:53.982073Z",
     "shell.execute_reply": "2026-01-24T15:11:53.981286Z"
    },
    "papermill": {
     "duration": 4.554282,
     "end_time": "2026-01-24T15:11:53.984275",
     "exception": false,
     "start_time": "2026-01-24T15:11:49.429993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers torch datasets scikit-learn tqdm accelerate optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724f249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:11:53.997844Z",
     "iopub.status.busy": "2026-01-24T15:11:53.997234Z",
     "iopub.status.idle": "2026-01-24T15:11:54.002755Z",
     "shell.execute_reply": "2026-01-24T15:11:54.002165Z"
    },
    "papermill": {
     "duration": 0.013883,
     "end_time": "2026-01-24T15:11:54.004082",
     "exception": false,
     "start_time": "2026-01-24T15:11:53.990199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "LOG_DIR = \"/kaggle/working\"\n",
    "LOG_FILE = os.path.join(LOG_DIR, \"train.log\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(LOG_FILE, mode=\"w\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "    ],\n",
    "    force=True,   # <<< QUAN TRỌNG\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1df8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:11:54.016266Z",
     "iopub.status.busy": "2026-01-24T15:11:54.015809Z",
     "iopub.status.idle": "2026-01-24T15:11:57.881450Z",
     "shell.execute_reply": "2026-01-24T15:11:57.880652Z"
    },
    "papermill": {
     "duration": 3.87347,
     "end_time": "2026-01-24T15:11:57.883017",
     "exception": false,
     "start_time": "2026-01-24T15:11:54.009547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Setup\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "def set_seed(seed=42): # Cố định random seed để kết quả reproducible\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "logger.info(f\"✓ Setup complete. Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"  GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0d207",
   "metadata": {
    "papermill": {
     "duration": 0.005724,
     "end_time": "2026-01-24T15:11:57.894697",
     "exception": false,
     "start_time": "2026-01-24T15:11:57.888973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Thiết kế chính\n",
    "\n",
    "- TaskConfig: Encapsulate toàn bộ thông tin về label schema\n",
    "- Dễ dàng thêm tác vụ mới bằng cách tạo config mới\n",
    "- ignore_labels: Linh hoạt định nghĩa labels không tính trong evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aefd5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:11:57.907648Z",
     "iopub.status.busy": "2026-01-24T15:11:57.907320Z",
     "iopub.status.idle": "2026-01-24T15:11:57.917617Z",
     "shell.execute_reply": "2026-01-24T15:11:57.917009Z"
    },
    "papermill": {
     "duration": 0.018432,
     "end_time": "2026-01-24T15:11:57.919006",
     "exception": false,
     "start_time": "2026-01-24T15:11:57.900574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class TaskConfig:\n",
    "    \"\"\"Configuration cho mỗi tác vụ\"\"\"\n",
    "    task_name: str\n",
    "    labels: List[str]\n",
    "    label2id: Dict[str, int]\n",
    "    id2label: Dict[int, str]\n",
    "    num_labels: int\n",
    "    ignore_labels: List[str] = None  # Labels bỏ qua khi eval\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, task_name: str, labels: List[str], ignore_labels: List[str] = None):\n",
    "        \"\"\"Factory method tạo config\"\"\"\n",
    "        label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "        id2label = {idx: label for label, idx in label2id.items()}\n",
    "        return cls(\n",
    "            task_name=task_name,\n",
    "            labels=labels,\n",
    "            label2id=label2id,\n",
    "            id2label=id2label,\n",
    "            num_labels=len(labels),\n",
    "            ignore_labels=ignore_labels or []\n",
    "        )\n",
    "\n",
    "# Config cho Sentence Punctuation\n",
    "PUNCTUATION_CONFIG = TaskConfig.create(\n",
    "    task_name=\"punctuation\",\n",
    "    labels=['O', '，', '。', '：', '、', '；', '？', '！'],\n",
    "    ignore_labels=['O']  # Bỏ qua token không có dấu khi eval\n",
    ")\n",
    "\n",
    "# Config cho Sentence Segmentation\n",
    "SEGMENTATION_CONFIG = TaskConfig.create(\n",
    "    task_name=\"segmentation\",\n",
    "    labels=['B', 'M', 'E', 'S'],\n",
    "    ignore_labels=[]  # Đánh giá tất cả các nhãn\n",
    ")\n",
    "\n",
    "# Training hyperparameters\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Hyperparameters chung\"\"\"\n",
    "    model_name: str = \"SIKU-BERT/sikubert\"\n",
    "    max_length: int = 256\n",
    "\n",
    "    # Hyperparameters to be tuned\n",
    "    batch_size: int = 64\n",
    "    learning_rate: float = 2e-5\n",
    "    num_epochs: int = 5\n",
    "    warmup_ratio: float = 0.1\n",
    "    weight_decay: float = 0.01\n",
    "    dropout: float = 0.1\n",
    "    max_grad_norm: float = 1.0\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping_patience: int = 3 # Kết quả val ko tăng 3 lần liên tiếp\n",
    "\n",
    "    # Fixed\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seed: int = 42\n",
    "    gradient_accumulation_steps: int = 1  # Tăng nếu GPU memory không đủ\n",
    "    fp16=True\n",
    "\n",
    "logger.info(\"✅ Configurations defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01de790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:11:57.932249Z",
     "iopub.status.busy": "2026-01-24T15:11:57.932012Z",
     "iopub.status.idle": "2026-01-24T15:11:57.935533Z",
     "shell.execute_reply": "2026-01-24T15:11:57.934881Z"
    },
    "papermill": {
     "duration": 0.011392,
     "end_time": "2026-01-24T15:11:57.936986",
     "exception": false,
     "start_time": "2026-01-24T15:11:57.925594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Select task\n",
    "TASK = \"segmentation\"  # or \"punctuation\"\n",
    "task_config = PUNCTUATION_CONFIG if TASK == \"punctuation\" else SEGMENTATION_CONFIG\n",
    "train_path='/kaggle/input/tbnl-sliding-window-256-128/segmentation_train.json'\n",
    "val_path='/kaggle/input/tbnl-sliding-window-256-128/segmentation_val.json'\n",
    "test_path='/kaggle/input/tbnl-sliding-window-256-128/segmentation_test.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a96f6",
   "metadata": {
    "papermill": {
     "duration": 0.005724,
     "end_time": "2026-01-24T15:11:57.948264",
     "exception": false,
     "start_time": "2026-01-24T15:11:57.942540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset & Preprocessing\n",
    "- Hỗ trợ character-level alignment (quan trọng cho Classical Chinese)\n",
    "- Xử lý special tokens ([CLS], [SEP], [PAD]) bằng label -100\n",
    "- Validate input để phát hiện lỗi sớm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c362ee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:11:57.961081Z",
     "iopub.status.busy": "2026-01-24T15:11:57.960493Z",
     "iopub.status.idle": "2026-01-24T15:12:08.406020Z",
     "shell.execute_reply": "2026-01-24T15:12:08.405299Z"
    },
    "papermill": {
     "duration": 10.453486,
     "end_time": "2026-01-24T15:12:08.407414",
     "exception": false,
     "start_time": "2026-01-24T15:11:57.953928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "class ClassicalChineseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset cho token classification tasks.\n",
    "    \n",
    "    Input format:\n",
    "        texts: List[str] - danh sách văn bản (mỗi văn bản là chuỗi ký tự)\n",
    "        labels: List[List[str]] - nhãn tương ứng cho mỗi ký tự\n",
    "    \n",
    "    Example:\n",
    "        texts = [\"天地玄黃\", \"宇宙洪荒\"]\n",
    "        labels = [['B', 'M', 'M', 'E'], ['B', 'M', 'M', 'E']]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: List[List[str]],\n",
    "        tokenizer,\n",
    "        config: TaskConfig,\n",
    "        max_length: int = 256\n",
    "    ):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Validate data\n",
    "        assert len(texts) == len(labels), \"texts và labels phải cùng độ dài\"\n",
    "        for text, label_seq in zip(texts, labels):\n",
    "            assert len(text) == len(label_seq), \\\n",
    "                f\"Text và labels không khớp: {len(text)} vs {len(label_seq)}\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label_seq = self.labels[idx]\n",
    "        \n",
    "        # Tokenize với is_split_into_words=True để track alignment\n",
    "        # SikuBERT thường tokenize từng ký tự -> 1:1 mapping\n",
    "        tokenized = self.tokenizer(\n",
    "            list(text),  # Convert sang list ký tự\n",
    "            is_split_into_words=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Align labels với subword tokens\n",
    "        # SikuBERT: thường 1 char = 1 token, nhưng vẫn cần xử lý edge cases\n",
    "        word_ids = tokenized.word_ids(batch_index=0)\n",
    "        label_ids = []\n",
    "        \n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                # [CLS], [SEP], [PAD] -> assign -100 (ignored by CrossEntropyLoss)\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                # Map label sang ID\n",
    "                label = label_seq[word_id]\n",
    "                label_ids.append(self.config.label2id[label])\n",
    "        \n",
    "        return {\n",
    "            'input_ids': tokenized['input_ids'].squeeze(0),\n",
    "            'attention_mask': tokenized['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label_ids, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_texts: List[str],\n",
    "    train_labels: List[List[str]],\n",
    "    val_texts: List[str],\n",
    "    val_labels: List[List[str]],\n",
    "    tokenizer,\n",
    "    config: TaskConfig,\n",
    "    training_config: TrainingConfig\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"Factory function tạo train & val dataloaders\"\"\"\n",
    "    \n",
    "    train_dataset = ClassicalChineseDataset(\n",
    "        train_texts, train_labels, tokenizer, config, training_config.max_length\n",
    "    )\n",
    "    val_dataset = ClassicalChineseDataset(\n",
    "        val_texts, val_labels, tokenizer, config, training_config.max_length\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=training_config.batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=training_config.batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "logger.info(\"✅ Dataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87baf87b",
   "metadata": {
    "papermill": {
     "duration": 0.005826,
     "end_time": "2026-01-24T15:12:08.419268",
     "exception": false,
     "start_time": "2026-01-24T15:12:08.413442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Definition\n",
    "\n",
    "- Module hóa: Dễ dàng thêm BiLSTM/CNN qua parameter extra_layer_type\n",
    "- Extensible: Placeholder cho CRF (sẽ return logits, CRF xử lý bên ngoài)\n",
    "- Linear head đơn giản nhưng hiệu quả cho baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fec6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:08.432051Z",
     "iopub.status.busy": "2026-01-24T15:12:08.431688Z",
     "iopub.status.idle": "2026-01-24T15:12:08.464697Z",
     "shell.execute_reply": "2026-01-24T15:12:08.464044Z"
    },
    "papermill": {
     "duration": 0.041183,
     "end_time": "2026-01-24T15:12:08.466040",
     "exception": false,
     "start_time": "2026-01-24T15:12:08.424857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SikuBERTForTokenClassification(nn.Module):\n",
    "    \"\"\"\n",
    "    SikuBERT với classification head có thể mở rộng.\n",
    "    \n",
    "    Architecture:\n",
    "        BERT Encoder -> [Optional: Extra Layers] -> Classification Head\n",
    "    \n",
    "    Thiết kế module hóa cho phép:\n",
    "        - Thay Linear head bằng CRF\n",
    "        - Thêm BiLSTM/CNN layers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        num_labels: int,\n",
    "        dropout: float = 0.1,\n",
    "        use_extra_layer: bool = False,\n",
    "        extra_layer_type: str = None,  # 'lstm', 'cnn', None\n",
    "        cnn_kernel_sizes: list = None,  # Mới: kernel sizes cho CNN\n",
    "        cnn_num_filters: int = 128      # Mới: số filters cho CNN\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone: SikuBERT\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Extra layers (placeholder cho future extensions)\n",
    "        self.extra_layer = None\n",
    "        self.extra_layer_type = extra_layer_type\n",
    "        \n",
    "        if use_extra_layer:\n",
    "            if extra_layer_type == 'lstm':\n",
    "                # BiLSTM layer\n",
    "                self.extra_layer = nn.LSTM(\n",
    "                    self.hidden_size,\n",
    "                    self.hidden_size // 2,\n",
    "                    batch_first=True,\n",
    "                    bidirectional=True\n",
    "                )\n",
    "                classifier_input_size = self.hidden_size\n",
    "                \n",
    "            elif extra_layer_type == 'cnn':\n",
    "                # CNN layer với multiple kernel sizes\n",
    "                if cnn_kernel_sizes is None:\n",
    "                    cnn_kernel_sizes = [3, 5, 7]  # default\n",
    "                \n",
    "                self.cnn_kernel_sizes = cnn_kernel_sizes\n",
    "                self.cnn_num_filters = cnn_num_filters\n",
    "                \n",
    "                # Tạo multiple Conv1d layers với kernel sizes khác nhau\n",
    "                self.convs = nn.ModuleList([\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=self.hidden_size,\n",
    "                        out_channels=cnn_num_filters,\n",
    "                        kernel_size=k,\n",
    "                        padding=k//2  # Same padding\n",
    "                    )\n",
    "                    for k in cnn_kernel_sizes\n",
    "                ])\n",
    "                \n",
    "                # Output size = số filters × số kernels\n",
    "                classifier_input_size = cnn_num_filters * len(cnn_kernel_sizes)\n",
    "                \n",
    "        else:\n",
    "            classifier_input_size = self.hidden_size\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(classifier_input_size, num_labels)\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss_fct = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        labels=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Returns:\n",
    "            dict với keys: loss (nếu labels được cung cấp), logits\n",
    "        \"\"\"\n",
    "        # BERT encoding\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = outputs.last_hidden_state  # (batch, seq_len, hidden)\n",
    "        \n",
    "        # Extra layers (nếu có)\n",
    "        if self.extra_layer is not None:\n",
    "            if self.extra_layer_type == 'lstm':\n",
    "                sequence_output, _ = self.extra_layer(sequence_output)\n",
    "                \n",
    "            elif self.extra_layer_type == 'cnn':\n",
    "                # CNN expects (batch, channels, seq_len)\n",
    "                # Input: (batch, seq_len, hidden) -> transpose to (batch, hidden, seq_len)\n",
    "                cnn_input = sequence_output.transpose(1, 2)\n",
    "                \n",
    "                # Apply multiple convolutions\n",
    "                conv_outputs = []\n",
    "                for conv in self.convs:\n",
    "                    # conv output: (batch, num_filters, seq_len)\n",
    "                    conv_out = F.relu(conv(cnn_input))\n",
    "                    conv_outputs.append(conv_out)\n",
    "                \n",
    "                # Concatenate along channel dimension\n",
    "                # (batch, num_filters * num_kernels, seq_len)\n",
    "                combined = torch.cat(conv_outputs, dim=1)\n",
    "                \n",
    "                # Transpose back: (batch, seq_len, num_filters * num_kernels)\n",
    "                sequence_output = combined.transpose(1, 2)\n",
    "        \n",
    "        # Dropout + Classification\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)  # (batch, seq_len, num_labels)\n",
    "        \n",
    "        # Calculate loss nếu có labels\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Flatten để tính loss\n",
    "            loss = self.loss_fct(\n",
    "                logits.view(-1, self.classifier.out_features),\n",
    "                labels.view(-1)\n",
    "            )\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits': logits\n",
    "        }\n",
    "\n",
    "logger.info(\"✅ Model class with CNN support defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30285ad4",
   "metadata": {
    "papermill": {
     "duration": 0.005645,
     "end_time": "2026-01-24T15:12:08.477377",
     "exception": false,
     "start_time": "2026-01-24T15:12:08.471732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation & EvalHan2024-style Scorer\n",
    "- Stateful scorer: accumulate predictions qua batches\n",
    "- Bỏ qua padding và ignore labels theo đúng EvalHan2024\n",
    "- Per-label metrics + overall macro average\n",
    "- Pretty printing cho dễ đọc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad04039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:08.489920Z",
     "iopub.status.busy": "2026-01-24T15:12:08.489329Z",
     "iopub.status.idle": "2026-01-24T15:12:08.495221Z",
     "shell.execute_reply": "2026-01-24T15:12:08.494652Z"
    },
    "papermill": {
     "duration": 0.013552,
     "end_time": "2026-01-24T15:12:08.496512",
     "exception": false,
     "start_time": "2026-01-24T15:12:08.482960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dataclasses import asdict\n",
    "\n",
    "def save_eval_results(\n",
    "    results: dict,\n",
    "    task_config: TaskConfig,\n",
    "    training_config: TrainingConfig,\n",
    "    split: str,                       # \"val\" | \"test\"\n",
    "    output_dir: str = \"eval_results\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Lưu kết quả đánh giá + siêu tham số ra file JSON (EvalHan2024 style)\n",
    "    \"\"\"\n",
    "    assert split in [\"val\", \"test\"], \"split must be 'val' or 'test'\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_tag = training_config.model_name.replace(\"/\", \"_\")\n",
    "\n",
    "    filename = (\n",
    "        f\"{task_config.task_name}_\"\n",
    "        f\"{split}_\"\n",
    "        f\"{model_tag}_\"\n",
    "        f\"{timestamp}.json\"\n",
    "    )\n",
    "\n",
    "    save_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    payload = {\n",
    "        \"meta\": {\n",
    "            \"task\": task_config.task_name,\n",
    "            \"split\": split,\n",
    "            \"timestamp\": timestamp\n",
    "        },\n",
    "        \"model\": {\n",
    "            \"name\": training_config.model_name,\n",
    "            \"num_labels\": task_config.num_labels,\n",
    "            \"labels\": task_config.labels,\n",
    "            \"ignore_labels\": task_config.ignore_labels\n",
    "        },\n",
    "        \"training_config\": asdict(training_config),\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    logger.info(f\"[INFO] Saved EvalHan results to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649df18b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:08.508871Z",
     "iopub.status.busy": "2026-01-24T15:12:08.508648Z",
     "iopub.status.idle": "2026-01-24T15:12:08.522909Z",
     "shell.execute_reply": "2026-01-24T15:12:08.522241Z"
    },
    "papermill": {
     "duration": 0.022138,
     "end_time": "2026-01-24T15:12:08.524254",
     "exception": false,
     "start_time": "2026-01-24T15:12:08.502116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from collections import defaultdict\n",
    "\n",
    "class EvalHanScorer:\n",
    "    \"\"\"\n",
    "    Scorer theo chuẩn EvalHan2024.\n",
    "    \n",
    "    Tính Precision/Recall/F1 cho:\n",
    "        - Từng loại label riêng biệt\n",
    "        - Overall (macro average)\n",
    "    \n",
    "    Bỏ qua:\n",
    "        - Padding tokens (label = -100)\n",
    "        - Labels trong ignore_labels\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: TaskConfig):\n",
    "        self.config = config\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset statistics\"\"\"\n",
    "        self.all_predictions = []\n",
    "        self.all_labels = []\n",
    "    \n",
    "    def add_batch(self, predictions, labels):\n",
    "        \"\"\"\n",
    "        Thêm một batch predictions và labels.\n",
    "        \n",
    "        Args:\n",
    "            predictions: tensor (batch, seq_len) - predicted label IDs\n",
    "            labels: tensor (batch, seq_len) - ground truth label IDs\n",
    "        \"\"\"\n",
    "        # Flatten và filter\n",
    "        predictions = predictions.view(-1).cpu().numpy()\n",
    "        labels = labels.view(-1).cpu().numpy()\n",
    "        \n",
    "        # Lọc padding (-100) và ignore labels\n",
    "        valid_mask = labels != -100\n",
    "        \n",
    "        for pred, label in zip(predictions[valid_mask], labels[valid_mask]):\n",
    "            label_str = self.config.id2label[label]\n",
    "            # Bỏ qua ignore labels (ví dụ: 'O' trong punctuation)\n",
    "            if label_str not in self.config.ignore_labels:\n",
    "                self.all_predictions.append(pred)\n",
    "                self.all_labels.append(label)\n",
    "    \n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        Tính metrics theo chuẩn EvalHan2024.\n",
    "        \n",
    "        Returns:\n",
    "            dict với structure:\n",
    "                {\n",
    "                    'per_label': {\n",
    "                        'label_name': {'precision': ..., 'recall': ..., 'f1': ...}\n",
    "                    },\n",
    "                    'overall': {'precision': ..., 'recall': ..., 'f1': ...}\n",
    "                }\n",
    "        \"\"\"\n",
    "        if len(self.all_predictions) == 0:\n",
    "            return {'overall': {'precision': 0, 'recall': 0, 'f1': 0}, 'per_label': {}}\n",
    "        \n",
    "        # Get unique labels (exclude ignore labels)\n",
    "        unique_labels = []\n",
    "        for label_str in self.config.labels:\n",
    "            if label_str not in self.config.ignore_labels:\n",
    "                unique_labels.append(self.config.label2id[label_str])\n",
    "        \n",
    "        # Tính metrics cho từng label\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            self.all_labels,\n",
    "            self.all_predictions,\n",
    "            labels=unique_labels,\n",
    "            average=None,\n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        # Format results\n",
    "        results = {'per_label': {}}\n",
    "        \n",
    "        for idx, label_id in enumerate(unique_labels):\n",
    "            label_name = self.config.id2label[label_id]\n",
    "            results['per_label'][label_name] = {\n",
    "                'precision': float(precision[idx]),\n",
    "                'recall': float(recall[idx]),\n",
    "                'f1': float(f1[idx]),\n",
    "                'support': int(support[idx])\n",
    "            }\n",
    "        \n",
    "        # Overall metrics (macro average)\n",
    "        results['overall'] = {\n",
    "            'precision': float(np.mean(precision)),\n",
    "            'recall': float(np.mean(recall)),\n",
    "            'f1': float(np.mean(f1))\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_results(self, results):\n",
    "        \"\"\"Pretty print results\"\"\"\n",
    "        logger.info(f\"\\n{'='*70}\")\n",
    "        logger.info(f\"EvalHan2024 Results - {self.config.task_name.upper()}\")\n",
    "        logger.info(f\"{'='*70}\")\n",
    "        \n",
    "        # Per-label results\n",
    "        logger.info(f\"\\n{'Label':<10} {'Precision':<12} {'Recall':<12} {'F1':<12} {'Support':<10}\")\n",
    "        logger.info(f\"{'-'*70}\")\n",
    "        \n",
    "        for label_name, metrics in results['per_label'].items():\n",
    "            logger.info(f\"{label_name:<10} \"\n",
    "                  f\"{metrics['precision']:<12.4f} \"\n",
    "                  f\"{metrics['recall']:<12.4f} \"\n",
    "                  f\"{metrics['f1']:<12.4f} \"\n",
    "                  f\"{metrics['support']:<10}\")\n",
    "        \n",
    "        # Overall results\n",
    "        logger.info(f\"{'-'*70}\")\n",
    "        logger.info(f\"{'OVERALL':<10} \"\n",
    "              f\"{results['overall']['precision']:<12.4f} \"\n",
    "              f\"{results['overall']['recall']:<12.4f} \"\n",
    "              f\"{results['overall']['f1']:<12.4f}\")\n",
    "        logger.info(f\"{'='*70}\\n\")\n",
    "\n",
    "def evaluate_model(\n",
    "    model,\n",
    "    dataloader,\n",
    "    config: TaskConfig,\n",
    "    device,\n",
    "    split: str,\n",
    "    training_config: TrainingConfig,\n",
    "    output_dir: str = \"eval_results\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate model trên validation/test set.\n",
    "    \n",
    "    Returns:\n",
    "        dict: EvalHan2024-style results\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    scorer = EvalHanScorer(config)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "            \n",
    "            # Add to scorer\n",
    "            scorer.add_batch(predictions, labels)\n",
    "    \n",
    "    # Compute metrics\n",
    "    results = scorer.compute()\n",
    "    scorer.print_results(results)\n",
    "\n",
    "    save_eval_results(\n",
    "        results=results,\n",
    "        task_config=config,\n",
    "        training_config=training_config,\n",
    "        split=split,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "logger.info(\"✅ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503f55d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:08.537284Z",
     "iopub.status.busy": "2026-01-24T15:12:08.536820Z",
     "iopub.status.idle": "2026-01-24T15:12:08.568642Z",
     "shell.execute_reply": "2026-01-24T15:12:08.567862Z"
    },
    "papermill": {
     "duration": 0.040288,
     "end_time": "2026-01-24T15:12:08.570277",
     "exception": false,
     "start_time": "2026-01-24T15:12:08.529989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "========================================================================\n",
    "DATA LOADING UTILITIES\n",
    "========================================================================\n",
    "Hỗ trợ nhiều format phổ biến cho Classical Chinese data:\n",
    "- JSON format\n",
    "- CoNLL format (IOB style)\n",
    "- Plain text with inline labels\n",
    "- CSV format\n",
    "========================================================================\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import csv\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================================\n",
    "# FORMAT 1: JSON Format\n",
    "# ============================================================================\n",
    "\n",
    "def load_json_format(file_path: str) -> Tuple[List[str], List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Load data từ JSON format.\n",
    "    \n",
    "    Expected JSON structure:\n",
    "    [\n",
    "        {\n",
    "            \"text\": \"天地玄黃宇宙洪荒\",\n",
    "            \"labels\": [\"O\", \"O\", \"O\", \"，\", \"O\", \"O\", \"O\", \"。\"]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "    \n",
    "    Returns:\n",
    "        texts: List[str]\n",
    "        labels: List[List[str]]\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    texts = [item['text'] for item in data]\n",
    "    labels = [item['labels'] for item in data]\n",
    "    \n",
    "    logger.info(f\"✓ Loaded {len(texts)} samples from {file_path}\")\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "def save_json_format(texts: List[str], labels: List[List[str]], output_path: str):\n",
    "    \"\"\"Save data to JSON format\"\"\"\n",
    "    data = [{'text': t, 'labels': l} for t, l in zip(texts, labels)]\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    logger.info(f\"✓ Saved {len(texts)} samples to {output_path}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FORMAT 2: CoNLL Format (Character-level)\n",
    "# ============================================================================\n",
    "\n",
    "def load_conll_format(file_path: str) -> Tuple[List[str], List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Load data từ CoNLL-style format.\n",
    "    \n",
    "    Expected format (character per line, blank line separates samples):\n",
    "    天 O\n",
    "    地 O\n",
    "    玄 O\n",
    "    黃 ，\n",
    "    \n",
    "    宇 O\n",
    "    宙 O\n",
    "    ...\n",
    "    \n",
    "    Returns:\n",
    "        texts: List[str]\n",
    "        labels: List[List[str]]\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "    current_text = []\n",
    "    current_labels = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line:  # Blank line = new sample\n",
    "                if current_text:\n",
    "                    texts.append(''.join(current_text))\n",
    "                    labels.append(current_labels)\n",
    "                    current_text = []\n",
    "                    current_labels = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    char, label = parts[0], parts[1]\n",
    "                    current_text.append(char)\n",
    "                    current_labels.append(label)\n",
    "        \n",
    "        # Don't forget last sample\n",
    "        if current_text:\n",
    "            texts.append(''.join(current_text))\n",
    "            labels.append(current_labels)\n",
    "    \n",
    "    logger.info(f\"✓ Loaded {len(texts)} samples from {file_path}\")\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "def save_conll_format(texts: List[str], labels: List[List[str]], output_path: str):\n",
    "    \"\"\"Save data to CoNLL format\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for text, label_seq in zip(texts, labels):\n",
    "            for char, label in zip(text, label_seq):\n",
    "                f.write(f\"{char} {label}\\n\")\n",
    "            f.write(\"\\n\")  # Blank line between samples\n",
    "    \n",
    "    logger.info(f\"✓ Saved {len(texts)} samples to {output_path}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FORMAT 3: Inline Format (text with embedded punctuation)\n",
    "# ============================================================================\n",
    "\n",
    "def load_inline_punctuation(file_path: str, \n",
    "                           punctuation_marks: List[str] = None) -> Tuple[List[str], List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Load text với dấu câu inline, convert thành format chuẩn.\n",
    "    \n",
    "    Input: \"天地玄黃，宇宙洪荒。\"\n",
    "    Output: \n",
    "        text: \"天地玄黃宇宙洪荒\"\n",
    "        labels: ['O', 'O', 'O', 'O', '，', 'O', 'O', 'O', 'O', '。']\n",
    "    \n",
    "    Args:\n",
    "        file_path: path to file (one sample per line)\n",
    "        punctuation_marks: list of punctuation to extract\n",
    "    \n",
    "    Returns:\n",
    "        texts: List[str] (without punctuation)\n",
    "        labels: List[List[str]] (labels at character positions)\n",
    "    \"\"\"\n",
    "    if punctuation_marks is None:\n",
    "        punctuation_marks = ['，', '。', '：', '、', '；', '？', '！']\n",
    "    \n",
    "    punct_set = set(punctuation_marks)\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            current_text = []\n",
    "            current_labels = []\n",
    "            \n",
    "            for i, char in enumerate(line):\n",
    "                if char in punct_set:\n",
    "                    # Dấu câu gán cho ký tự trước đó\n",
    "                    if current_labels:\n",
    "                        current_labels[-1] = char\n",
    "                else:\n",
    "                    current_text.append(char)\n",
    "                    current_labels.append('O')\n",
    "            \n",
    "            if current_text:\n",
    "                texts.append(''.join(current_text))\n",
    "                labels.append(current_labels)\n",
    "    \n",
    "    logger.info(f\"✓ Loaded {len(texts)} samples from {file_path}\")\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FORMAT 4: CSV Format\n",
    "# ============================================================================\n",
    "\n",
    "def load_csv_format(file_path: str, \n",
    "                   text_column: str = 'text',\n",
    "                   label_column: str = 'labels',\n",
    "                   delimiter: str = ',') -> Tuple[List[str], List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Load data từ CSV.\n",
    "    \n",
    "    Expected CSV columns:\n",
    "        text,labels\n",
    "        \"天地玄黃\",\"O O O ，\"\n",
    "    \n",
    "    Args:\n",
    "        file_path: path to CSV\n",
    "        text_column: name of text column\n",
    "        label_column: name of labels column\n",
    "        delimiter: CSV delimiter\n",
    "    \n",
    "    Returns:\n",
    "        texts: List[str]\n",
    "        labels: List[List[str]]\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f, delimiter=delimiter)\n",
    "        for row in reader:\n",
    "            text = row[text_column]\n",
    "            label_str = row[label_column]\n",
    "            \n",
    "            # Parse labels (assume space-separated)\n",
    "            label_list = label_str.strip().split()\n",
    "            \n",
    "            texts.append(text)\n",
    "            labels.append(label_list)\n",
    "    \n",
    "    logger.info(f\"✓ Loaded {len(texts)} samples from {file_path}\")\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FORMAT 5: BEMS from sentence boundaries\n",
    "# ============================================================================\n",
    "\n",
    "def create_bems_labels_from_sentences(sentences: List[str]) -> Tuple[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Convert list of sentences thành text + BEMS labels.\n",
    "    \n",
    "    Input: [\"天地玄黃\", \"宇宙洪荒\"]\n",
    "    Output:\n",
    "        text: \"天地玄黃宇宙洪荒\"\n",
    "        labels: ['B','M','M','E','B','M','M','E']\n",
    "    \n",
    "    Args:\n",
    "        sentences: List of sentences\n",
    "    \n",
    "    Returns:\n",
    "        text: concatenated text\n",
    "        labels: BEMS labels\n",
    "    \"\"\"\n",
    "    text = ''.join(sentences)\n",
    "    labels = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        length = len(sentence)\n",
    "        if length == 1:\n",
    "            labels.append('S')\n",
    "        else:\n",
    "            labels.append('B')\n",
    "            labels.extend(['M'] * (length - 2))\n",
    "            labels.append('E')\n",
    "    \n",
    "    return text, labels\n",
    "\n",
    "\n",
    "def load_sentence_file_to_bems(file_path: str, \n",
    "                               sentence_delimiter: str = '\\n') -> Tuple[List[str], List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Load file với sentences (one per line hoặc separated by delimiter),\n",
    "    convert thành BEMS format.\n",
    "    \n",
    "    Input file:\n",
    "        天地玄黃\n",
    "        宇宙洪荒\n",
    "        \n",
    "        日月盈昃\n",
    "        辰宿列張\n",
    "    \n",
    "    (blank line separates documents)\n",
    "    \n",
    "    Returns:\n",
    "        texts: List[str]\n",
    "        labels: List[List[str]] (BEMS)\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "    current_sentences = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line:  # Blank line = new document\n",
    "                if current_sentences:\n",
    "                    text, label_seq = create_bems_labels_from_sentences(current_sentences)\n",
    "                    texts.append(text)\n",
    "                    labels.append(label_seq)\n",
    "                    current_sentences = []\n",
    "            else:\n",
    "                current_sentences.append(line)\n",
    "        \n",
    "        # Last document\n",
    "        if current_sentences:\n",
    "            text, label_seq = create_bems_labels_from_sentences(current_sentences)\n",
    "            texts.append(text)\n",
    "            labels.append(label_seq)\n",
    "    \n",
    "    logger.info(f\"✓ Loaded {len(texts)} samples from {file_path}\")\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# AUTO-DETECT FORMAT\n",
    "# ============================================================================\n",
    "\n",
    "def load_data_auto(file_path: str, **kwargs) -> Tuple[List[str], List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Tự động detect format và load data.\n",
    "    \n",
    "    Args:\n",
    "        file_path: path to data file\n",
    "        **kwargs: additional arguments for specific loaders\n",
    "    \n",
    "    Returns:\n",
    "        texts: List[str]\n",
    "        labels: List[List[str]]\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    suffix = file_path.suffix.lower()\n",
    "    \n",
    "    logger.info(f\"Auto-detecting format for: {file_path}\")\n",
    "    \n",
    "    if suffix == '.json':\n",
    "        return load_json_format(file_path)\n",
    "    elif suffix == '.csv':\n",
    "        return load_csv_format(file_path, **kwargs)\n",
    "    elif suffix in ['.txt', '.conll']:\n",
    "        # Try to detect: CoNLL vs inline vs sentence format\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline().strip()\n",
    "        \n",
    "        if '\\t' in first_line or (len(first_line.split()) == 2):\n",
    "            logger.info(\"  Detected: CoNLL format\")\n",
    "            return load_conll_format(file_path)\n",
    "        else:\n",
    "            logger.info(\"  Detected: Plain text format\")\n",
    "            logger.info(\"  Assuming inline punctuation - specify format if incorrect\")\n",
    "            return load_inline_punctuation(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported format: {suffix}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATION UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def validate_data(texts: List[str], labels: List[List[str]]) -> bool:\n",
    "    \"\"\"\n",
    "    Validate data integrity.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if valid, raises exception otherwise\n",
    "    \"\"\"\n",
    "    assert len(texts) == len(labels), \\\n",
    "        f\"Length mismatch: {len(texts)} texts vs {len(labels)} label sequences\"\n",
    "    \n",
    "    for i, (text, label_seq) in enumerate(zip(texts, labels)):\n",
    "        assert len(text) == len(label_seq), \\\n",
    "            f\"Sample {i}: {len(text)} chars vs {len(label_seq)} labels\\n\" \\\n",
    "            f\"  Text: {text[:50]}...\\n\" \\\n",
    "            f\"  Labels: {label_seq[:50]}...\"\n",
    "    \n",
    "    logger.info(f\"✓ Data validation passed: {len(texts)} samples\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def print_data_stats(texts: List[str], labels: List[List[str]], task_config):\n",
    "    \"\"\"Print statistics about dataset\"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    logger.info(f\"\\n{'='*70}\")\n",
    "    logger.info(\"DATA STATISTICS\")\n",
    "    logger.info(f\"{'='*70}\")\n",
    "    logger.info(f\"Total samples: {len(texts)}\")\n",
    "    logger.info(f\"Avg text length: {sum(len(t) for t in texts) / len(texts):.1f} chars\")\n",
    "    logger.info(f\"Min/Max length: {min(len(t) for t in texts)} / {max(len(t) for t in texts)}\")\n",
    "    \n",
    "    # Label distribution\n",
    "    all_labels = [label for label_seq in labels for label in label_seq]\n",
    "    label_counts = Counter(all_labels)\n",
    "    \n",
    "    logger.info(f\"\\nLabel distribution:\")\n",
    "    for label in task_config.labels:\n",
    "        count = label_counts.get(label, 0)\n",
    "        pct = 100 * count / len(all_labels) if all_labels else 0\n",
    "        logger.info(f\"  {label}: {count:>8} ({pct:>5.2f}%)\")\n",
    "    \n",
    "    logger.info(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Example usage:\n",
    "\n",
    "# Auto-detect format\n",
    "texts, labels = load_data_auto('/kaggle/input/mydata/train.json')\n",
    "\n",
    "# Specific format\n",
    "texts, labels = load_json_format('/kaggle/input/mydata/train.json')\n",
    "texts, labels = load_conll_format('/kaggle/input/mydata/train.conll')\n",
    "\n",
    "# Validate\n",
    "validate_data(texts, labels)\n",
    "print_data_stats(texts, labels, PUNCTUATION_CONFIG)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9523ead4",
   "metadata": {
    "papermill": {
     "duration": 0.006825,
     "end_time": "2026-01-24T15:12:08.584190",
     "exception": false,
     "start_time": "2026-01-24T15:12:08.577365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Procedure\n",
    "- Gradient clipping để stability\n",
    "- Learning rate warmup (quan trọng cho BERT-based models)\n",
    "- Early stopping để tránh overfitting\n",
    "- Checkpoint best model theo F1 score\n",
    "- Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572d725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:08.599369Z",
     "iopub.status.busy": "2026-01-24T15:12:08.598917Z",
     "iopub.status.idle": "2026-01-24T15:12:08.605574Z",
     "shell.execute_reply": "2026-01-24T15:12:08.604911Z"
    },
    "papermill": {
     "duration": 0.016061,
     "end_time": "2026-01-24T15:12:08.607110",
     "exception": false,
     "start_time": "2026-01-24T15:12:08.591049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping handler\"\"\"\n",
    "    \n",
    "    def __init__(self, patience: int = 3, min_delta: float = 0.0, mode: str = 'max'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience: Number of epochs to wait for improvement\n",
    "            min_delta: Minimum change to qualify as improvement\n",
    "            mode: 'max' for metrics to maximize (F1), 'min' for loss\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "    \n",
    "    def __call__(self, score: float, epoch: int) -> bool:\n",
    "        \"\"\"\n",
    "        Check if should stop training.\n",
    "        \n",
    "        Returns:\n",
    "            True if should stop, False otherwise\n",
    "        \"\"\"\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            return False\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            improved = score > (self.best_score + self.min_delta)\n",
    "        else:\n",
    "            improved = score < (self.best_score - self.min_delta)\n",
    "        \n",
    "        if improved:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                return True\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561ae7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:08.622222Z",
     "iopub.status.busy": "2026-01-24T15:12:08.621954Z",
     "iopub.status.idle": "2026-01-24T15:12:10.290894Z",
     "shell.execute_reply": "2026-01-24T15:12:10.290084Z"
    },
    "papermill": {
     "duration": 1.678433,
     "end_time": "2026-01-24T15:12:10.292440",
     "exception": false,
     "start_time": "2026-01-24T15:12:08.614007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from typing import Optional\n",
    "import optuna\n",
    "\n",
    "def train_with_early_stopping(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    task_config: TaskConfig,\n",
    "    training_config: TrainingConfig,\n",
    "    trial: Optional[optuna.Trial] = None,\n",
    "    save_path: str = \"models/best_model_cnn.pt\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train model with early stopping.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial (for pruning)\n",
    "    \n",
    "    Returns:\n",
    "        best_val_f1: Best validation F1 score\n",
    "    \"\"\"\n",
    "    set_seed(training_config.seed)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=training_config.learning_rate,\n",
    "        weight_decay=training_config.weight_decay\n",
    "    )\n",
    "    \n",
    "    # Scheduler\n",
    "    total_steps = len(train_loader) * training_config.num_epochs\n",
    "    warmup_steps = int(total_steps * training_config.warmup_ratio)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=training_config.early_stopping_patience,\n",
    "        mode='max'\n",
    "    )\n",
    "    \n",
    "    best_val_f1 = 0.0\n",
    "    \n",
    "    for epoch in range(training_config.num_epochs):\n",
    "        # ====================================================================\n",
    "        # TRAINING\n",
    "        # ====================================================================\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{training_config.num_epochs}\")\n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(training_config.device)\n",
    "            attention_mask = batch['attention_mask'].to(training_config.device)\n",
    "            labels = batch['labels'].to(training_config.device)\n",
    "            \n",
    "            # Forward\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs['loss']\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), training_config.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            loss_value = loss.item()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "            # Train log\n",
    "            \n",
    "            logger.info(\n",
    "                \"Epoch %d | Step %d/%d | Loss %.4f\",\n",
    "                epoch + 1, step, len(train_loader), loss_value\n",
    "            )\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # VALIDATION\n",
    "        # ====================================================================\n",
    "        val_results = evaluate_model(model, val_loader, task_config, training_config.device, \"test\", training_config)\n",
    "        val_f1 = val_results['overall']['f1']\n",
    "        \n",
    "        logger.info(f\"\\nEpoch {epoch+1}/{training_config.num_epochs}:\")\n",
    "        logger.info(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "        logger.info(f\"  Val F1:     {val_f1:.4f}\")\n",
    "        logger.info(f\"  Val Prec:   {val_results['overall']['precision']:.4f}\")\n",
    "        logger.info(f\"  Val Recall: {val_results['overall']['recall']:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            logger.info(f\"  ✓ Saved best model (F1: {best_val_f1:.4f})\")\n",
    "        \n",
    "        # Optuna pruning (optional)\n",
    "        if trial is not None:\n",
    "            trial.report(val_f1, epoch)\n",
    "            if trial.should_prune():\n",
    "                logger.info(f\"  ✂️ Trial pruned at epoch {epoch+1}\")\n",
    "                raise optuna.TrialPruned()\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stopping(val_f1, epoch):\n",
    "            logger.info(f\"\\n⏹️  Early stopping triggered!\")\n",
    "            logger.info(f\"  No improvement for {early_stopping.patience} epochs\")\n",
    "            logger.info(f\"  Best epoch: {early_stopping.best_epoch + 1}\")\n",
    "            logger.info(f\"  Best Val F1: {best_val_f1:.4f}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    \n",
    "    return best_val_f1\n",
    "\n",
    "logger.info(\"✅ Training functions with early stopping defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28311687",
   "metadata": {
    "papermill": {
     "duration": 0.005776,
     "end_time": "2026-01-24T15:12:10.304485",
     "exception": false,
     "start_time": "2026-01-24T15:12:10.298709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# OPTUNA BAYESIAN OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8fa7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:10.317733Z",
     "iopub.status.busy": "2026-01-24T15:12:10.317301Z",
     "iopub.status.idle": "2026-01-24T15:12:10.336889Z",
     "shell.execute_reply": "2026-01-24T15:12:10.336160Z"
    },
    "papermill": {
     "duration": 0.027869,
     "end_time": "2026-01-24T15:12:10.338202",
     "exception": false,
     "start_time": "2026-01-24T15:12:10.310333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "from optuna.importance import MeanDecreaseImpurityImportanceEvaluator\n",
    "\n",
    "def create_optuna_objective(\n",
    "    train_texts, train_labels,\n",
    "    val_texts, val_labels,\n",
    "    tokenizer,\n",
    "    task_config: TaskConfig,\n",
    "    base_training_config: TrainingConfig\n",
    "):\n",
    "    \"\"\"\n",
    "    Create Optuna objective function.\n",
    "    \n",
    "    Returns a function that Optuna will optimize.\n",
    "    \"\"\"\n",
    "    \n",
    "    def objective(trial: optuna.Trial):\n",
    "        \"\"\"\n",
    "        Objective function for Optuna to maximize.\n",
    "        \n",
    "        Samples hyperparameters and returns validation F1.\n",
    "        \"\"\"\n",
    "        \n",
    "        # ====================================================================\n",
    "        # SAMPLE HYPERPARAMETERS\n",
    "        # ====================================================================\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "        # batch_size = trial.suggest_categorical('batch_size', [8, 16, 32, 64])\n",
    "        batch_size = trial.suggest_categorical('batch_size', [64])\n",
    "        warmup_ratio = trial.suggest_float('warmup_ratio', 0.0, 0.2)\n",
    "        weight_decay = trial.suggest_float('weight_decay', 0.0, 0.1)\n",
    "        dropout = trial.suggest_float('dropout', 0.1, 0.3)\n",
    "        \n",
    "        logger.info(f\"\\n{'='*70}\")\n",
    "        logger.info(f\"Trial {trial.number}\")\n",
    "        logger.info(f\"{'='*70}\")\n",
    "        logger.info(f\"Hyperparameters:\")\n",
    "        logger.info(f\"  learning_rate: {learning_rate:.2e}\")\n",
    "        logger.info(f\"  batch_size:    {batch_size}\")\n",
    "        logger.info(f\"  warmup_ratio:  {warmup_ratio:.3f}\")\n",
    "        logger.info(f\"  weight_decay:  {weight_decay:.3f}\")\n",
    "        logger.info(f\"  dropout:       {dropout:.3f}\")\n",
    "        logger.info(f\"{'='*70}\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CREATE DATALOADERS\n",
    "        # ====================================================================\n",
    "        train_dataset = ClassicalChineseDataset(\n",
    "            train_texts, train_labels, tokenizer, task_config, base_training_config.max_length\n",
    "        )\n",
    "        val_dataset = ClassicalChineseDataset(\n",
    "            val_texts, val_labels, tokenizer, task_config, base_training_config.max_length\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CREATE MODEL\n",
    "        # ====================================================================\n",
    "        model = SikuBERTForTokenClassification(\n",
    "            model_name=base_training_config.model_name,\n",
    "            num_labels=task_config.num_labels,\n",
    "            dropout=dropout,\n",
    "            use_extra_layer=True,\n",
    "            extra_layer_type='cnn',\n",
    "            cnn_kernel_sizes=[3, 5, 7], # Custom kernels\n",
    "            cnn_num_filters=256 # Nhiều filters hơn\n",
    "        ).to(base_training_config.device)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CREATE TRAINING CONFIG\n",
    "        # ====================================================================\n",
    "        trial_config = TrainingConfig(\n",
    "            model_name=base_training_config.model_name,\n",
    "            max_length=base_training_config.max_length,\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=base_training_config.num_epochs,\n",
    "            warmup_ratio=warmup_ratio,\n",
    "            weight_decay=weight_decay,\n",
    "            dropout=dropout,\n",
    "            early_stopping_patience=base_training_config.early_stopping_patience,\n",
    "            device=base_training_config.device,\n",
    "            seed=base_training_config.seed\n",
    "        )\n",
    "        \n",
    "        # ====================================================================\n",
    "        # TRAIN WITH EARLY STOPPING\n",
    "        # ====================================================================\n",
    "        try:\n",
    "            best_val_f1 = train_with_early_stopping(\n",
    "                model, train_loader, val_loader,\n",
    "                task_config, trial_config,\n",
    "                trial=trial,\n",
    "                save_path=f\"models/optuna_trial_{trial.number}_best_cnn.pt\"\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"\\n✓ Trial {trial.number} completed: Val F1 = {best_val_f1:.4f}\")\n",
    "            \n",
    "            return best_val_f1\n",
    "            \n",
    "        except optuna.TrialPruned:\n",
    "            # Trial was pruned by Optuna\n",
    "            raise\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.info(f\"\\n❌ Trial {trial.number} failed: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    return objective\n",
    "\n",
    "\n",
    "def run_optuna_optimization(\n",
    "    train_texts, train_labels,\n",
    "    val_texts, val_labels,\n",
    "    tokenizer,\n",
    "    task_config: TaskConfig,\n",
    "    base_training_config: TrainingConfig,\n",
    "    n_trials: int = 30,\n",
    "    study_name: str = \"sikubert_tuning\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Run Optuna hyperparameter optimization.\n",
    "    \n",
    "    Args:\n",
    "        n_trials: Number of trials to run\n",
    "        study_name: Name of the study\n",
    "    \n",
    "    Returns:\n",
    "        study: Optuna study object with all results\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(f\"\\n{'='*70}\")\n",
    "    logger.info(f\"OPTUNA BAYESIAN OPTIMIZATION\")\n",
    "    logger.info(f\"{'='*70}\")\n",
    "    logger.info(f\"Task: {task_config.task_name}\")\n",
    "    logger.info(f\"Number of trials: {n_trials}\")\n",
    "    logger.info(f\"Early stopping patience: {base_training_config.early_stopping_patience}\")\n",
    "    logger.info(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Create objective function\n",
    "    objective = create_optuna_objective(\n",
    "        train_texts, train_labels,\n",
    "        val_texts, val_labels,\n",
    "        tokenizer, task_config, base_training_config\n",
    "    )\n",
    "    \n",
    "    # Create study\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction='maximize',  # Maximize F1\n",
    "        pruner=optuna.pruners.MedianPruner(  # Prune unpromising trials\n",
    "            n_startup_trials=5,\n",
    "            n_warmup_steps=3\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Run optimization\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=n_trials,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # RESULTS\n",
    "    # ========================================================================\n",
    "    logger.info(f\"\\n{'='*70}\")\n",
    "    logger.info(f\"OPTIMIZATION COMPLETE\")\n",
    "    logger.info(f\"{'='*70}\")\n",
    "    \n",
    "    logger.info(f\"\\n📊 Study Statistics:\")\n",
    "    logger.info(f\"  Completed trials: {len(study.trials)}\")\n",
    "    logger.info(f\"  Pruned trials:    {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "    logger.info(f\"  Failed trials:    {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "    \n",
    "    logger.info(f\"\\n🏆 Best Trial:\")\n",
    "    best_trial = study.best_trial\n",
    "    logger.info(f\"  Trial number:  {best_trial.number}\")\n",
    "    logger.info(f\"  Val F1:        {best_trial.value:.4f}\")\n",
    "    logger.info(f\"\\n  Best Hyperparameters:\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        if 'learning_rate' in key:\n",
    "            logger.info(f\"    {key}: {value:.2e}\")\n",
    "        else:\n",
    "            logger.info(f\"    {key}: {value}\")\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'study_name': study_name,\n",
    "        'task': task_config.task_name,\n",
    "        'n_trials': len(study.trials),\n",
    "        'best_trial': {\n",
    "            'number': best_trial.number,\n",
    "            'value': best_trial.value,\n",
    "            'params': best_trial.params\n",
    "        },\n",
    "        'all_trials': [\n",
    "            {\n",
    "                'number': t.number,\n",
    "                'value': t.value,\n",
    "                'params': t.params,\n",
    "                'state': str(t.state)\n",
    "            }\n",
    "            for t in study.trials\n",
    "        ],\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(f'outputs/optuna_{task_config.task_name}_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"\\n✓ Results saved to outputs/optuna_{task_config.task_name}_results.json\")\n",
    "    \n",
    "    return study\n",
    "\n",
    "logger.info(\"✅ Optuna optimization functions defined\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def visualize_optuna_results(study, task_name: str):\n",
    "    \"\"\"Visualize Optuna results\"\"\"\n",
    "    try:\n",
    "        # Plot 1: Optimization history\n",
    "        fig1 = plot_optimization_history(study)\n",
    "        fig1.write_html(f'outputs/optuna_{task_name}_history.html')\n",
    "        logger.info(f\"✓ Saved optimization history plot\")\n",
    "        \n",
    "        # Plot 2: Parameter importances\n",
    "        # FIX: Use the Random Forest evaluator to avoid the NumPy/fANOVA ValueError\n",
    "        fig2 = plot_param_importances(\n",
    "            study, \n",
    "            evaluator=MeanDecreaseImpurityImportanceEvaluator()\n",
    "        )\n",
    "        \n",
    "        # FIX: Save as HTML to avoid needing the 'kaleido' package\n",
    "        fig2.write_html(f'outputs/optuna_{task_name}_importance.html')\n",
    "        logger.info(f\"✓ Saved parameter importance plot\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        logger.info(f\"⚠️ Visualization failed: {e}\")\n",
    "        logger.info(\"   Ensure 'plotly' is installed.\")\n",
    "    except Exception as e:\n",
    "        logger.info(f\"⚠️ An unexpected error occurred during visualization: {e}\")\n",
    "\n",
    "logger.info(\"✅ Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb3d7e",
   "metadata": {
    "papermill": {
     "duration": 0.006033,
     "end_time": "2026-01-24T15:12:10.350126",
     "exception": false,
     "start_time": "2026-01-24T15:12:10.344093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15008b73",
   "metadata": {
    "papermill": {
     "duration": 0.00589,
     "end_time": "2026-01-24T15:12:10.361942",
     "exception": false,
     "start_time": "2026-01-24T15:12:10.356052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde97477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:10.375039Z",
     "iopub.status.busy": "2026-01-24T15:12:10.374767Z",
     "iopub.status.idle": "2026-01-24T15:12:11.179534Z",
     "shell.execute_reply": "2026-01-24T15:12:11.178868Z"
    },
    "papermill": {
     "duration": 0.813139,
     "end_time": "2026-01-24T15:12:11.181070",
     "exception": false,
     "start_time": "2026-01-24T15:12:10.367931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_config = TrainingConfig(early_stopping_patience=3)\n",
    "\n",
    "# 2. Setup\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_config.model_name)\n",
    "logger.info(\"✓ Tokenizer loaded\")\n",
    "\n",
    "logger.info(f\"\\n{'='*70}\")\n",
    "logger.info(f\"Training: {task_config.task_name.upper()}\")\n",
    "logger.info(f\"Labels: {task_config.labels}\")\n",
    "logger.info(f\"Device: {base_config.device}\")\n",
    "logger.info(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eb8e6e",
   "metadata": {
    "papermill": {
     "duration": 0.006183,
     "end_time": "2026-01-24T15:12:11.194182",
     "exception": false,
     "start_time": "2026-01-24T15:12:11.187999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25fc45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:11.207637Z",
     "iopub.status.busy": "2026-01-24T15:12:11.207378Z",
     "iopub.status.idle": "2026-01-24T15:12:21.687077Z",
     "shell.execute_reply": "2026-01-24T15:12:21.686305Z"
    },
    "papermill": {
     "duration": 10.488654,
     "end_time": "2026-01-24T15:12:21.689031",
     "exception": false,
     "start_time": "2026-01-24T15:12:11.200377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load your data\n",
    "train_texts, train_labels = load_data_auto(train_path)\n",
    "val_texts, val_labels = load_data_auto(val_path)\n",
    "\n",
    "# train_texts=train_texts[:5]\n",
    "# train_labels=train_labels[:5]\n",
    "# val_texts=val_texts[:5]\n",
    "# val_labels=val_labels[:5]\n",
    "\n",
    "# Validate data\n",
    "logger.info(\"\\n📊 Validating data...\")\n",
    "validate_data(train_texts, train_labels)\n",
    "validate_data(val_texts, val_labels)\n",
    "\n",
    "logger.info(f\"\\n✓ Data loaded successfully:\")\n",
    "logger.info(f\"  - Training set: {len(train_texts)} samples\")\n",
    "logger.info(f\"  - Validation set: {len(val_texts)} samples\")\n",
    "logger.info(f\"  - Train/Val ratio: {len(train_texts)/len(val_texts):.1f}:1\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    train_texts, train_labels, val_texts, val_labels,\n",
    "    tokenizer, task_config, training_config=base_config\n",
    ")\n",
    "\n",
    "print_data_stats(train_texts, train_texts, PUNCTUATION_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9908ce",
   "metadata": {
    "papermill": {
     "duration": 0.00731,
     "end_time": "2026-01-24T15:12:21.704238",
     "exception": false,
     "start_time": "2026-01-24T15:12:21.696928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Optuna to fine best Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0af07e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:21.720041Z",
     "iopub.status.busy": "2026-01-24T15:12:21.719557Z",
     "iopub.status.idle": "2026-01-24T15:12:21.722670Z",
     "shell.execute_reply": "2026-01-24T15:12:21.722024Z"
    },
    "papermill": {
     "duration": 0.012581,
     "end_time": "2026-01-24T15:12:21.724039",
     "exception": false,
     "start_time": "2026-01-24T15:12:21.711458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study = run_optuna_optimization(\n",
    "#     train_texts, train_labels,\n",
    "#     val_texts, val_labels,\n",
    "#     tokenizer, task_config, base_config,\n",
    "#     n_trials=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f88ae",
   "metadata": {
    "papermill": {
     "duration": 0.007135,
     "end_time": "2026-01-24T15:12:21.738482",
     "exception": false,
     "start_time": "2026-01-24T15:12:21.731347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualize Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc03a00f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:21.753766Z",
     "iopub.status.busy": "2026-01-24T15:12:21.753484Z",
     "iopub.status.idle": "2026-01-24T15:12:21.756464Z",
     "shell.execute_reply": "2026-01-24T15:12:21.755846Z"
    },
    "papermill": {
     "duration": 0.012125,
     "end_time": "2026-01-24T15:12:21.757780",
     "exception": false,
     "start_time": "2026-01-24T15:12:21.745655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize_optuna_results(study, TASK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2a80d",
   "metadata": {
    "papermill": {
     "duration": 0.007191,
     "end_time": "2026-01-24T15:12:21.772210",
     "exception": false,
     "start_time": "2026-01-24T15:12:21.765019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train final model with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab35f7ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:21.787750Z",
     "iopub.status.busy": "2026-01-24T15:12:21.787475Z",
     "iopub.status.idle": "2026-01-24T15:12:21.790947Z",
     "shell.execute_reply": "2026-01-24T15:12:21.790314Z"
    },
    "papermill": {
     "duration": 0.012804,
     "end_time": "2026-01-24T15:12:21.792296",
     "exception": false,
     "start_time": "2026-01-24T15:12:21.779492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_params = study.best_params\n",
    "# final_config = TrainingConfig(\n",
    "#     learning_rate=best_params['learning_rate'],\n",
    "#     batch_size=best_params['batch_size'],\n",
    "#     warmup_ratio=best_params['warmup_ratio'],\n",
    "#     weight_decay=best_params['weight_decay'],\n",
    "#     dropout=best_params['dropout']\n",
    "# )\n",
    "\n",
    "# model = SikuBERTForTokenClassification(\n",
    "#     final_config.model_name,\n",
    "#     task_config.num_labels,\n",
    "#     use_extra_layer=True,\n",
    "#     extra_layer_type='cnn',\n",
    "#     cnn_kernel_sizes=[3, 5, 7], # Custom kernels\n",
    "#     cnn_num_filters=256 # Nhiều filters hơn\n",
    "# ).to(final_config.device)\n",
    "\n",
    "# logger.info(f\"✓ Model created ({sum(p.numel() for p in model.parameters()):,} parameters)\")\n",
    "# save_path = f\"models/best_{task_config.task_name}_model_cnn.pt\"\n",
    "\n",
    "# best_val_f1 = train_with_early_stopping(\n",
    "#     model, train_loader, val_loader,\n",
    "#     task_config, final_config,\n",
    "#     trial=None,\n",
    "#     save_path=save_path\n",
    "# )\n",
    "\n",
    "# logger.info(\"\\n🎉 Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64534e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T15:12:21.808156Z",
     "iopub.status.busy": "2026-01-24T15:12:21.807734Z",
     "iopub.status.idle": "2026-01-24T20:56:44.967021Z",
     "shell.execute_reply": "2026-01-24T20:56:44.966199Z"
    },
    "papermill": {
     "duration": 20663.168924,
     "end_time": "2026-01-24T20:56:44.968485",
     "exception": false,
     "start_time": "2026-01-24T15:12:21.799561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training only\n",
    "final_config=base_config\n",
    "\n",
    "model = SikuBERTForTokenClassification(\n",
    "    base_config.model_name,\n",
    "    task_config.num_labels,\n",
    "    use_extra_layer=True,\n",
    "    extra_layer_type='cnn',\n",
    "    cnn_kernel_sizes=[3, 5, 7], # Custom kernels\n",
    "    cnn_num_filters=256 # Nhiều filters hơn\n",
    ").to(base_config.device)\n",
    "\n",
    "logger.info(f\"✓ Model created ({sum(p.numel() for p in model.parameters()):,} parameters)\")\n",
    "save_path = f\"models/best_{task_config.task_name}_model_cnn.pt\"\n",
    "\n",
    "best_val_f1 = train_with_early_stopping(\n",
    "    model, train_loader, val_loader,\n",
    "    task_config, base_config,\n",
    "    trial=None,\n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "logger.info(\"\\n🎉 Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931ad62",
   "metadata": {
    "papermill": {
     "duration": 0.960673,
     "end_time": "2026-01-24T20:56:46.943865",
     "exception": false,
     "start_time": "2026-01-24T20:56:45.983192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c03bc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T20:56:48.985138Z",
     "iopub.status.busy": "2026-01-24T20:56:48.984117Z",
     "iopub.status.idle": "2026-01-24T21:01:45.416220Z",
     "shell.execute_reply": "2026-01-24T21:01:45.415451Z"
    },
    "papermill": {
     "duration": 297.46219,
     "end_time": "2026-01-24T21:01:45.417708",
     "exception": false,
     "start_time": "2026-01-24T20:56:47.955518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(\"\\n\" + \"=\"*70)\n",
    "logger.info(\"⭐ FINAL TEST SET EVALUATION\")\n",
    "logger.info(\"=\"*70)\n",
    "logger.info(\"This is the OFFICIAL performance evaluation\")\n",
    "logger.info(\"Model has NEVER seen test data during training!\")\n",
    "logger.info(\"=\"*70)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "\n",
    "test_texts, test_labels = load_data_auto(test_path)\n",
    "\n",
    "# Create test loader\n",
    "test_dataset = ClassicalChineseDataset(\n",
    "    test_texts, test_labels, tokenizer, task_config, final_config.max_length\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=final_config.batch_size, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "logger.info(\"\\n🎯 Evaluating on TEST set...\")\n",
    "test_results = evaluate_model(model, test_loader, task_config, final_config.device, \"test\", final_config)\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "final_results = {\n",
    "    'task': task_config.task_name,\n",
    "    'test': test_results['overall'],  # ← OFFICIAL RESULT\n",
    "    'test_per_label': test_results['per_label']\n",
    "}\n",
    "\n",
    "with open(f'outputs/{task_config.task_name}_test_results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "logger.info(\"\\n\" + \"=\"*70)\n",
    "logger.info(\"✅ OFFICIAL TEST RESULTS:\")\n",
    "logger.info(f\"   Precision: {test_results['overall']['precision']:.4f}\")\n",
    "logger.info(f\"   Recall:    {test_results['overall']['recall']:.4f}\")\n",
    "logger.info(f\"   F1 Score:  {test_results['overall']['f1']:.4f}\")\n",
    "logger.info(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280df743",
   "metadata": {
    "papermill": {
     "duration": 0.924598,
     "end_time": "2026-01-24T21:01:47.377513",
     "exception": false,
     "start_time": "2026-01-24T21:01:46.452915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# INFERENCE & DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0aecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:01:49.340502Z",
     "iopub.status.busy": "2026-01-24T21:01:49.339809Z",
     "iopub.status.idle": "2026-01-24T21:01:49.345463Z",
     "shell.execute_reply": "2026-01-24T21:01:49.344868Z"
    },
    "papermill": {
     "duration": 0.937458,
     "end_time": "2026-01-24T21:01:49.346997",
     "exception": false,
     "start_time": "2026-01-24T21:01:48.409539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_text(model, text, tokenizer, config, device):\n",
    "    \"\"\"Predict labels for text\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    tokenized = tokenizer(list(text), is_split_into_words=True, \n",
    "                         return_tensors='pt', padding=True, truncation=True)\n",
    "    input_ids = tokenized['input_ids'].to(device)\n",
    "    attention_mask = tokenized['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "    \n",
    "    word_ids = tokenized.word_ids(batch_index=0)\n",
    "    predicted_labels = []\n",
    "    \n",
    "    for idx, word_id in enumerate(word_ids):\n",
    "        if word_id is not None:\n",
    "            pred_id = predictions[0][idx].item()\n",
    "            predicted_labels.append(config.id2label[pred_id])\n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e2992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:01:51.326073Z",
     "iopub.status.busy": "2026-01-24T21:01:51.325760Z",
     "iopub.status.idle": "2026-01-24T21:01:51.366190Z",
     "shell.execute_reply": "2026-01-24T21:01:51.365528Z"
    },
    "papermill": {
     "duration": 0.998188,
     "end_time": "2026-01-24T21:01:51.367459",
     "exception": false,
     "start_time": "2026-01-24T21:01:50.369271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "#\"綱鑑會編卷五十三。文安劉德芳匡訏正崑山葉澐麁輯錄唐紀高宗皇帝諱治，字爲善，太宗第九子。初封𣈆珏後立爲皇太子在位三十四年崩壽五十六綱。\"\n",
    "#\"綱鑑會編卷五十三 | 文安劉德芳匡訏正崑山葉澐麁輯錄唐紀高宗皇帝諱治 | 字爲善 | 太宗第九子/初封𣈆珏後立爲皇太子在位三十四年崩壽五十六綱 | \"\n",
    "\n",
    "test_text = \"綱鑑會編卷五十三文安劉德芳匡訏正崑山葉澐麁輯錄唐紀高宗皇帝諱治字爲善太宗第九子初封𣈆珏後立爲皇太子在位三十四年崩壽五十六綱\"\n",
    "predicted = predict_text(model, test_text, tokenizer, task_config, final_config.device)\n",
    "\n",
    "logger.info(f\"\\n{'='*70}\")\n",
    "logger.info(\"DEMO INFERENCE\")\n",
    "logger.info(f\"{'='*70}\")\n",
    "logger.info(f\"\\nText: {test_text}\")\n",
    "logger.info(f\"Labels: {predicted}\")  # Show first 20\n",
    "\n",
    "if TASK == \"punctuation\":\n",
    "    result = ''.join([c if l == 'O' else c+l for c, l in zip(test_text, predicted)])\n",
    "    logger.info(f\"\\nPunctuated: {result}\")\n",
    "else:\n",
    "    sentences = []\n",
    "    current = []\n",
    "    for c, l in zip(test_text, predicted):\n",
    "        current.append(c)\n",
    "        if l in ['E', 'S']:\n",
    "            sentences.append(''.join(current))\n",
    "            current = []\n",
    "    if current:\n",
    "        sentences.append(''.join(current))\n",
    "    logger.info(f\"\\nSegmented: {' | '.join(sentences)}\")\n",
    "\n",
    "logger.info(f\"\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae5de6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:01:53.412527Z",
     "iopub.status.busy": "2026-01-24T21:01:53.412233Z",
     "iopub.status.idle": "2026-01-24T21:01:53.416498Z",
     "shell.execute_reply": "2026-01-24T21:01:53.415924Z"
    },
    "papermill": {
     "duration": 1.039242,
     "end_time": "2026-01-24T21:01:53.417977",
     "exception": false,
     "start_time": "2026-01-24T21:01:52.378735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_punctuation_labels(text, labels):\n",
    "    \"\"\"\n",
    "    text: str\n",
    "    labels: List[str] with punctuation symbols or 'O'\n",
    "    \"\"\"\n",
    "    output = []\n",
    "\n",
    "    for ch, label in zip(text, labels):\n",
    "        output.append(ch)\n",
    "        if label != \"O\":\n",
    "            output.append(label)\n",
    "\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4c791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:01:55.371675Z",
     "iopub.status.busy": "2026-01-24T21:01:55.371347Z",
     "iopub.status.idle": "2026-01-24T21:01:55.375722Z",
     "shell.execute_reply": "2026-01-24T21:01:55.375025Z"
    },
    "papermill": {
     "duration": 1.026476,
     "end_time": "2026-01-24T21:01:55.377130",
     "exception": false,
     "start_time": "2026-01-24T21:01:54.350654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_segmentation_inline(text, labels, sep=\" | \"):\n",
    "    output = []\n",
    "\n",
    "    for ch, label in zip(text, labels):\n",
    "        output.append(ch)\n",
    "        if label in (\"E\", \"S\"):\n",
    "            output.append(sep)\n",
    "\n",
    "    return \"\".join(output).rstrip(sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dcac79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:01:57.332284Z",
     "iopub.status.busy": "2026-01-24T21:01:57.331584Z",
     "iopub.status.idle": "2026-01-24T21:01:57.337395Z",
     "shell.execute_reply": "2026-01-24T21:01:57.336832Z"
    },
    "papermill": {
     "duration": 0.936658,
     "end_time": "2026-01-24T21:01:57.338846",
     "exception": false,
     "start_time": "2026-01-24T21:01:56.402188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_labels(model, text, tokenizer, config, device):\n",
    "    \"\"\"\n",
    "    Predict labels for ONE text (character-level)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    chars = list(text)\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        chars,\n",
    "        is_split_into_words=True,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    input_ids = tokenized[\"input_ids\"].to(device)\n",
    "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        preds = torch.argmax(outputs[\"logits\"], dim=-1)[0]\n",
    "\n",
    "    word_ids = tokenized.word_ids()\n",
    "    pred_labels = []\n",
    "\n",
    "    for idx, word_id in enumerate(word_ids):\n",
    "        if word_id is not None:\n",
    "            label_id = preds[idx].item()\n",
    "            pred_labels.append(config.id2label[label_id])\n",
    "\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e348463",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:01:59.403141Z",
     "iopub.status.busy": "2026-01-24T21:01:59.402838Z",
     "iopub.status.idle": "2026-01-24T21:01:59.409461Z",
     "shell.execute_reply": "2026-01-24T21:01:59.408879Z"
    },
    "papermill": {
     "duration": 1.038431,
     "end_time": "2026-01-24T21:01:59.410813",
     "exception": false,
     "start_time": "2026-01-24T21:01:58.372382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_test_set(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    config,\n",
    "    device,\n",
    "    test_path,\n",
    "    output_path,\n",
    "):\n",
    "    import json\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        test_data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for sample in tqdm(test_data):\n",
    "        text = sample[\"text\"]\n",
    "        gold_labels = sample[\"labels\"]\n",
    "\n",
    "        pred_labels = predict_labels(\n",
    "            model=model,\n",
    "            text=text,\n",
    "            tokenizer=tokenizer,\n",
    "            config=config,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # assert len(text) == len(gold_labels) == len(pred_labels)\n",
    "\n",
    "        if config.task_name == \"punctuation\":\n",
    "            gold_text = apply_punctuation_labels(text, gold_labels)\n",
    "            pred_text = apply_punctuation_labels(text, pred_labels)\n",
    "\n",
    "        elif config.task_name == \"segmentation\":\n",
    "            gold_text = apply_segmentation_inline(text, gold_labels)\n",
    "            pred_text = apply_segmentation_inline(text, pred_labels)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task: {config.task_name}\")\n",
    "\n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"gold_labels\": gold_labels,\n",
    "            \"pred_labels\": pred_labels,\n",
    "            \"gold_text_labeled\": gold_text,\n",
    "            \"pred_text_labeled\": pred_text,\n",
    "        })\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b47b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T21:02:01.417000Z",
     "iopub.status.busy": "2026-01-24T21:02:01.416291Z",
     "iopub.status.idle": "2026-01-24T21:07:52.454100Z",
     "shell.execute_reply": "2026-01-24T21:07:52.453237Z"
    },
    "papermill": {
     "duration": 352.109637,
     "end_time": "2026-01-24T21:07:52.456317",
     "exception": false,
     "start_time": "2026-01-24T21:02:00.346680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test_set(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    config=task_config,\n",
    "    device=device,\n",
    "    test_path=test_path,\n",
    "    output_path=\"/kaggle/working/test_pred.json\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9310170,
     "sourceId": 14574924,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9227492,
     "sourceId": 14574931,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21369.626694,
   "end_time": "2026-01-24T21:07:56.480188",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-24T15:11:46.853494",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02634b51b2fe4e26962dc01ecc12c9a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03926edf7499468a89707dfee6c15ac7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_91e67b3701ea4d919713e981d7173c46",
       "placeholder": "​",
       "style": "IPY_MODEL_4aa6eb5e8aa343dea20523cd880cceb4",
       "tabbable": null,
       "tooltip": null,
       "value": " 144k/? [00:00&lt;00:00, 11.8MB/s]"
      }
     },
     "06796f795df94ea78c791d8caefd984b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0ad09dc949124a0895658b1544230673": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "13c7d83fe7654d65a4af43ac33ad4d06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15397d6534334249acc171fcf7842424": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_398833bb8691448f8335af3242f2a655",
       "placeholder": "​",
       "style": "IPY_MODEL_e91da014118e47019b35be3c3749e85b",
       "tabbable": null,
       "tooltip": null,
       "value": " 438M/438M [00:02&lt;00:00, 498MB/s]"
      }
     },
     "279b522f2289440ba08fc40bb54a46ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_02634b51b2fe4e26962dc01ecc12c9a6",
       "placeholder": "​",
       "style": "IPY_MODEL_cb55dfe15dd749829ab892754a350d0d",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "2ff6a41b4af64300a6498766c6b5d1a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "386941eea7c544839654a2f3de551a8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "398833bb8691448f8335af3242f2a655": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c52da87f4624f8cba0f7deb4bf0fcd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9352f0efcffb42568dc6a5e8c6b2cad1",
       "max": 659,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d1c555dc69114e79b2d26fa64268d9b0",
       "tabbable": null,
       "tooltip": null,
       "value": 659
      }
     },
     "3d4febbadf1a414a910ae23977d36ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "400768c9f9dc4ba0ad2c8c577b1a0f32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_279b522f2289440ba08fc40bb54a46ee",
        "IPY_MODEL_c83f375cfaeb4f938ff6aae0f608829d",
        "IPY_MODEL_77cb08c20a0047f2bc1867205f046de6"
       ],
       "layout": "IPY_MODEL_c5e74e41a79f4c55ad83093b16e0b2c9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "46c08bab62294c1cac96b729d1ce7ab3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_386941eea7c544839654a2f3de551a8c",
       "placeholder": "​",
       "style": "IPY_MODEL_e42383ee7b0f424a89d331688a9761a3",
       "tabbable": null,
       "tooltip": null,
       "value": " 659/659 [00:00&lt;00:00, 89.8kB/s]"
      }
     },
     "4a8613893ab54840a3436e9e83395699": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4aa6eb5e8aa343dea20523cd880cceb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "537be71a2691464099fd43216ed56de4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "550486e05857404a955edd61d50b7bba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "57ddd184bd7d48a496bea786d20f2e6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "748834d1670f421881a7b647514a8c22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77cb08c20a0047f2bc1867205f046de6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d2b3cfbd556497ba95e42da9a1b99dd",
       "placeholder": "​",
       "style": "IPY_MODEL_3d4febbadf1a414a910ae23977d36ed7",
       "tabbable": null,
       "tooltip": null,
       "value": " 438M/438M [00:01&lt;00:00, 400MB/s]"
      }
     },
     "7d2b3cfbd556497ba95e42da9a1b99dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88ac51b7e94849cdbc4f2733adf17b1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8dadbd4d2a094757aba69695707b41f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_57ddd184bd7d48a496bea786d20f2e6e",
       "max": 438219059,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4a8613893ab54840a3436e9e83395699",
       "tabbable": null,
       "tooltip": null,
       "value": 438219059
      }
     },
     "91d44f9128bc4768a0d18639121158ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a5c65376bac54f55a580bc5f64011a30",
       "placeholder": "​",
       "style": "IPY_MODEL_ba329eab07564ab19d080702f23162b8",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "91e67b3701ea4d919713e981d7173c46": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9352f0efcffb42568dc6a5e8c6b2cad1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a5c65376bac54f55a580bc5f64011a30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7b83db7afb9428bb57621254b3d3a9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_13c7d83fe7654d65a4af43ac33ad4d06",
       "placeholder": "​",
       "style": "IPY_MODEL_d0866b8993ef49f48d9bbbc67a2a8600",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "a97adee946e4498eb1af0f7d6ff9d6f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_537be71a2691464099fd43216ed56de4",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f5767ecc6811443eab713bed95be97f3",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "b3d63c6f11bb4a8da487c92fdc8c19a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5c8377509144893bbe09dc8b9885698": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ba095cb9725e416585697bf1088734e5",
        "IPY_MODEL_a97adee946e4498eb1af0f7d6ff9d6f9",
        "IPY_MODEL_03926edf7499468a89707dfee6c15ac7"
       ],
       "layout": "IPY_MODEL_88ac51b7e94849cdbc4f2733adf17b1b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b668b9cebdb146288e8d429eec37d63a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a7b83db7afb9428bb57621254b3d3a9f",
        "IPY_MODEL_8dadbd4d2a094757aba69695707b41f6",
        "IPY_MODEL_15397d6534334249acc171fcf7842424"
       ],
       "layout": "IPY_MODEL_b3d63c6f11bb4a8da487c92fdc8c19a4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ba095cb9725e416585697bf1088734e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2ff6a41b4af64300a6498766c6b5d1a9",
       "placeholder": "​",
       "style": "IPY_MODEL_550486e05857404a955edd61d50b7bba",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: "
      }
     },
     "ba329eab07564ab19d080702f23162b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c5e74e41a79f4c55ad83093b16e0b2c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c83f375cfaeb4f938ff6aae0f608829d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_748834d1670f421881a7b647514a8c22",
       "max": 438195020,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_06796f795df94ea78c791d8caefd984b",
       "tabbable": null,
       "tooltip": null,
       "value": 438195020
      }
     },
     "cb55dfe15dd749829ab892754a350d0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d0866b8993ef49f48d9bbbc67a2a8600": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d1c555dc69114e79b2d26fa64268d9b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e42383ee7b0f424a89d331688a9761a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e91da014118e47019b35be3c3749e85b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f05e02c88c1d434d80273b9aa815e730": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_91d44f9128bc4768a0d18639121158ed",
        "IPY_MODEL_3c52da87f4624f8cba0f7deb4bf0fcd5",
        "IPY_MODEL_46c08bab62294c1cac96b729d1ce7ab3"
       ],
       "layout": "IPY_MODEL_0ad09dc949124a0895658b1544230673",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f5767ecc6811443eab713bed95be97f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
